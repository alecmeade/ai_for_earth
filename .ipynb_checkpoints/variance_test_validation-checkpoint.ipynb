{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# To view tensorboard metrics\n",
    "# tensorboard --logdir=logs --port=6006 --bind_all\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from functools import partial\n",
    "from evolver import CrossoverType, MutationType, InitType, MatrixEvolver, VectorEvolver\n",
    "from unet import UNet\n",
    "from dataset_utils import PartitionType\n",
    "from cuda_utils import maybe_get_cuda_device, clear_cuda\n",
    "from landcover_dataloader import get_landcover_dataloaders, get_landcover_dataloader\n",
    "\n",
    "from ignite.contrib.handlers.tensorboard_logger import *\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, ConfusionMatrix, mIoU\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.utils import setup_logger\n",
    "from ignite.engine import Engine\n",
    "\n",
    "# Define directories for data, logging and model saving.\n",
    "base_dir = os.getcwd()\n",
    "dataset_name = \"landcover_large\"\n",
    "dataset_dir = os.path.join(base_dir, \"data/\" + dataset_name)\n",
    "\n",
    "experiment_name = \"dropout_single_point_finetuning_variance_validation\"\n",
    "model_name = \"best_model_9_validation_accuracy=0.8940.pt\"\n",
    "model_path = os.path.join(base_dir, \"logs/\" + dataset_name + \"/\" + model_name)\n",
    "log_dir = os.path.join(base_dir, \"logs/\" + dataset_name + \"_\" + experiment_name)\n",
    "\n",
    "# Create DataLoaders for each partition of Landcover data.\n",
    "dataloader_params = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 6,\n",
    "    'pin_memory': True}\n",
    "\n",
    "partition_types = [PartitionType.TRAIN, PartitionType.VALIDATION, \n",
    "                   PartitionType.FINETUNING, PartitionType.TEST]\n",
    "data_loaders = get_landcover_dataloaders(dataset_dir, \n",
    "                                         partition_types,\n",
    "                                         dataloader_params,\n",
    "                                         force_create_dataset=False)\n",
    "\n",
    "\n",
    "train_loader = data_loaders[0]\n",
    "finetuning_loader = data_loaders[2]\n",
    "\n",
    "dataloader_params['shuffle'] = False\n",
    "test_loader = get_landcover_dataloader(dataset_dir, PartitionType.TEST, dataloader_params)\n",
    "\n",
    "\n",
    "# Get GPU device if available.\n",
    "device = maybe_get_cuda_device()\n",
    "\n",
    "# Determine model and training params.\n",
    "params = {\n",
    "    'max_epochs': 10,\n",
    "    'n_classes': 4,\n",
    "    'in_channels': 4,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.001,\n",
    "    'log_steps': 1,\n",
    "    'save_top_n_models': 4,\n",
    "    'num_children': 300\n",
    "}\n",
    "\n",
    "\n",
    "clear_cuda()    \n",
    "model = UNet(in_channels = params['in_channels'],\n",
    "             n_classes = params['n_classes'],\n",
    "             depth = params['depth'])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "# Create Trainer or Evaluators\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=params['learning_rate'])\n",
    "\n",
    "# Determine metrics for evaluation.\n",
    "metrics = {\n",
    "        \"accuracy\": Accuracy(), \n",
    "        \"loss\": Loss(criterion),\n",
    "        \"mean_iou\": mIoU(ConfusionMatrix(num_classes = params['n_classes'])),\n",
    "}\n",
    "\n",
    "for batch in train_loader:\n",
    "    batch_x = batch[0]\n",
    "    _ = model(batch_x)\n",
    "    break\n",
    "    \n",
    "drop_out_layers = model.get_dropout_layers()\n",
    "del model, batch_x\n",
    "clear_cuda()\n",
    "\n",
    "\n",
    "results = {}\n",
    "for layer in drop_out_layers:\n",
    "    layer_name = layer.name\n",
    "    if layer_name in ['start', 'down_0', 'down_1', 'down_2', 'down_3', 'down_4', 'down_5', 'up_0', 'up_1']:\n",
    "        continue\n",
    "        \n",
    "    size = layer.x_size[1:]\n",
    "    sizes = [size]\n",
    "    clear_cuda()    \n",
    "    model = UNet(in_channels = params['in_channels'],\n",
    "                 n_classes = params['n_classes'],\n",
    "                 depth = params['depth'])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr=params['learning_rate'])\n",
    "    \n",
    "    num_channels = size[0]\n",
    "    evolver = VectorEvolver(num_channels, \n",
    "                            CrossoverType.UNIFORM,\n",
    "                            MutationType.FLIP_BIT, \n",
    "                            InitType.RANDOM, \n",
    "                            flip_bit_prob=0.25, \n",
    "                            flip_bit_decay=0.5)\n",
    "\n",
    "    log_dir_test = log_dir + \"_\" + layer_name\n",
    "    \n",
    "    results[layer_name] = defaultdict(list)\n",
    "\n",
    "    mask_vecs = []\n",
    "    prev_index = -1\n",
    "    current_index = 0\n",
    "    for i in range(0, params['num_children']):\n",
    "        mask_vecs.append(evolver.spawn_child())\n",
    "        \n",
    "\n",
    "    def mask_from_vec(vec, matrix_size):\n",
    "        mask = np.ones(matrix_size)\n",
    "        for i in range(len(vec)):\n",
    "            if vec[i] == 0:\n",
    "                mask[i, :, :] = 0\n",
    "\n",
    "            elif vec[i] == 1:\n",
    "                mask[i, :, :] = 1\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def dropout_finetune_step(engine, batch):\n",
    "        global prev_index\n",
    "        global current_index\n",
    "        if prev_index != current_index and current_index != 0:\n",
    "            prev_index = current_index\n",
    "            mask = mask_from_vec(mask_vecs[current_index - 1], size)\n",
    "            child_vec = evolver.spawn_child()\n",
    "            model.set_dropout_masks({layer_name: torch.tensor(mask, dtype=torch.float32).to(device)})                \n",
    "\n",
    "\n",
    "    # Create Trainer or Evaluators\n",
    "    trainer = Engine(dropout_finetune_step)\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    trainer.logger = setup_logger(\"Trainer\")\n",
    "    train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "    validation_evaluator.logger = setup_logger(\"Validation Evaluator\")\n",
    "        \n",
    "    # Tensorboard Logger setup below based on pytorch ignite example\n",
    "    # https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_tensorboard_logger.py\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def compute_metrics(engine):\n",
    "        \"\"\"Callback to compute metrics on the train and validation data.\"\"\"\n",
    "        validation_evaluator.run(test_loader)\n",
    "        global prev_index\n",
    "        global current_index\n",
    "        global results\n",
    "        global size\n",
    "        global mask_vecs\n",
    "        current_index += 1\n",
    "        for m in metrics.keys():\n",
    "            results[layer_name][m].append(metrics[m].compute())\n",
    "            metrics[m].reset()\n",
    "\n",
    "        if current_index == 1:\n",
    "            results[layer_name]['num_non_zero'].append(size[0])\n",
    "        else:\n",
    "            results[layer_name]['num_non_zero'].append(np.sum(mask_vecs[prev_index - 1]))\n",
    "\n",
    "        results[layer_name]['size'].append(size[0])\n",
    "\n",
    "\n",
    "    # Setup Tensor Board Logging    \n",
    "    tb_logger = TensorboardLogger(log_dir=log_dir_test)\n",
    "\n",
    "    for tag, evaluator in [ (\"validation\", validation_evaluator)]:\n",
    "        tb_logger.attach_output_handler(\n",
    "            evaluator,\n",
    "            event_name=Events.EPOCH_COMPLETED,\n",
    "            tag=tag,\n",
    "            metric_names=\"all\",\n",
    "            global_step_transform=global_step_from_engine(trainer),\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer.run(finetuning_loader, max_epochs=params['num_children'] + 1)\n",
    "    tb_logger.close()\n",
    "    \n",
    "    f, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    plt.suptitle(\"Layer: \" + layer_name)\n",
    "    ax[0].scatter(results[layer_name]['num_non_zero'][1:], results[layer_name]['accuracy'][1:])\n",
    "    ax[1].scatter(results[layer_name]['num_non_zero'][1:], results[layer_name]['loss'][1:])\n",
    "    ax[2].scatter(results[layer_name]['num_non_zero'][1:], [i.item() for i in results[layer_name]['mean_iou'][1:]])\n",
    "    ax[0].set_title(\"Accuracy\")\n",
    "    ax[1].set_title(\"Loss\")\n",
    "    ax[2].set_title(\"Mean IOU\")\n",
    "    ax[0].set_xlabel(\"Count Active Neurons\")\n",
    "    ax[1].set_xlabel(\"Count Active Neurons\")\n",
    "    ax[2].set_xlabel(\"Count Active Neurons\")\n",
    "\n",
    "    ax[0].axhline(results[layer_name]['accuracy'][0], label = \"Base Model Acc\", color='r')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].axhline(results[layer_name]['loss'][0], label = \"Base Model Loss\", color='r')\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].axhline(results[layer_name]['mean_iou'][0].item(), label = \"Base Model Mean IOU\", color='r')\n",
    "    ax[2].legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
