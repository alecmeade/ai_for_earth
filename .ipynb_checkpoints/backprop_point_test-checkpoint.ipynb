{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# To view tensorboard metrics\n",
    "# tensorboard --logdir=logs --port=6006 --bind_all\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from functools import partial\n",
    "from evolver import CrossoverType, MutationType, VectorEvolver, InitType\n",
    "from unet import UNet\n",
    "from dataset_utils import PartitionType\n",
    "from cuda_utils import maybe_get_cuda_device, clear_cuda\n",
    "from landcover_dataloader import get_landcover_dataloaders\n",
    "\n",
    "from ignite.contrib.handlers.tensorboard_logger import *\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, ConfusionMatrix, mIoU\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.utils import setup_logger\n",
    "from ignite.engine import Engine\n",
    "import sys\n",
    "\n",
    "# Define directories for data, logging and model saving.\n",
    "base_dir = os.getcwd()\n",
    "dataset_name = \"landcover_large\"\n",
    "dataset_dir = os.path.join(base_dir, \"data/\" + dataset_name)\n",
    "\n",
    "experiment_name = \"backprop_single_point_finetuning_test_test\"\n",
    "model_name = \"best_model_30_validation_accuracy=0.9409.pt\"\n",
    "model_path = os.path.join(base_dir, \"logs/\" + dataset_name + \"/\" + model_name)\n",
    "log_dir = os.path.join(base_dir, \"logs/\" + dataset_name + \"_\" + experiment_name)\n",
    "\n",
    "# Create DataLoaders for each partition of Landcover data.\n",
    "dataloader_params = {\n",
    "    'batch_size': 1,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 6,\n",
    "    'pin_memory': True}\n",
    "\n",
    "partition_types = [PartitionType.TRAIN, PartitionType.VALIDATION, \n",
    "                   PartitionType.FINETUNING, PartitionType.TEST]\n",
    "data_loaders = get_landcover_dataloaders(dataset_dir, \n",
    "                                         partition_types,\n",
    "                                         dataloader_params,\n",
    "                                         force_create_dataset=True)\n",
    "\n",
    "finetuning_loader = data_loaders[2]\n",
    "test_loader = data_loaders[3]\n",
    "\n",
    "# Get GPU device if available.\n",
    "device = maybe_get_cuda_device()\n",
    "\n",
    "# Determine model and training params.\n",
    "params = {\n",
    "    'max_epochs': 10,\n",
    "    'n_classes': 4,\n",
    "    'in_channels': 4,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'log_steps': 1,\n",
    "    'save_top_n_models': 4\n",
    "}\n",
    "\n",
    "clear_cuda()    \n",
    "model = UNet(in_channels = params['in_channels'],\n",
    "             n_classes = params['n_classes'],\n",
    "             depth = params['depth'])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=params['learning_rate'])\n",
    "\n",
    "\n",
    "# Determine metrics for evaluation.\n",
    "train_metrics = {\n",
    "        \"accuracy\": Accuracy(), \n",
    "        \"loss\": Loss(criterion),\n",
    "        \"mean_iou\": mIoU(ConfusionMatrix(num_classes = params['n_classes'])),\n",
    "        }\n",
    "\n",
    "validation_metrics = {\n",
    "        \"accuracy\": Accuracy(), \n",
    "        \"loss\": Loss(criterion),\n",
    "        \"mean_iou\": mIoU(ConfusionMatrix(num_classes = params['n_classes'])),\n",
    "\n",
    "}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in finetuning_loader:\n",
    "    batch_x = batch[0]\n",
    "    _ = model(batch_x)\n",
    "    break\n",
    "    \n",
    "drop_out_layers = model.get_dropout_layers()\n",
    "\n",
    "\n",
    "    \n",
    "def mask_from_vec(vec, matrix_size):\n",
    "    mask = np.ones(matrix_size)\n",
    "    for i in range(len(vec)):\n",
    "        if vec[i] == 0:\n",
    "            mask[i, :, :] = 0\n",
    "\n",
    "        elif vec[i] == 1:\n",
    "            mask[i, :, :] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "for layer in drop_out_layers:\n",
    "    layer_name = layer.name\n",
    "    size = layer.x_size[1:]\n",
    "    sizes = [size]\n",
    "    clear_cuda()    \n",
    "    model = UNet(in_channels = params['in_channels'],\n",
    "                 n_classes = params['n_classes'],\n",
    "                 depth = params['depth'])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr=params['learning_rate'])\n",
    "\n",
    "    num_channels = size[0]\n",
    "    evolver = VectorEvolver(num_channels, \n",
    "                            CrossoverType.UNIFORM,\n",
    "                            MutationType.FLIP_BIT, \n",
    "                            InitType.BINOMIAL, \n",
    "                            flip_bit_prob=None, \n",
    "                            flip_bit_decay=1.0,\n",
    "                            binomial_prob=0.8)\n",
    "\n",
    "    print(\"LAYER\", layer_name, size)\n",
    "    with torch.no_grad():\n",
    "        batch_x, batch_y = batch\n",
    "        loss = sys.float_info.max\n",
    "        child_mask_prev = None\n",
    "        for i in range(300):\n",
    "            child_vec = evolver.spawn_child()\n",
    "            child_mask = mask_from_vec(child_vec, size)\n",
    "            model.set_dropout_masks({layer_name: torch.tensor(child_mask, dtype=torch.float32)})\n",
    "            outputs = model(batch_x)\n",
    "            current_loss = criterion(outputs[:, :, 127:128,127:128], batch_y[:,127:128,127:128]).item()\n",
    "            evolver.add_child(child_mask, 1.0 / current_loss)\n",
    "            print(\"Current\", current_loss)\n",
    "            loss = min(loss, current_loss)\n",
    "            \n",
    "            if current_loss == 0.0:\n",
    "                current_loss = sys.float_info.max\n",
    "            else:\n",
    "                current_loss = 1.0 / current_loss\n",
    "\n",
    "            evolver.add_child(child_vec, current_loss)\n",
    "                \n",
    "            priority, best_child = evolver.get_best_child()\n",
    "            best_mask = mask_from_vec(best_child, size)\n",
    "            model.set_dropout_masks({layer_name: torch.tensor(best_mask, dtype=torch.float32).to(device)})\n",
    "            \n",
    "            \n",
    "            \n",
    "#             f, ax = plt.subplots(1, 3, figsize=(20, 8))\n",
    "#             ax[0].imshow((np.array(batch_y.detach().numpy()[0, :, :])))\n",
    "#             ax[1].imshow(np.argmax(np.moveaxis(np.array(outputs.detach().numpy()[0, :, :, :]), [0],[ 2]), axis=2))\n",
    "#             ax[2].imshow(child_mask[0, :, :])\n",
    "              \n",
    "#             child_mask_prev = child_mask\n",
    "#             plt.show()\n",
    "        print(\"best_loss\", 1.0/evolver.get_best_child()[0])\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
