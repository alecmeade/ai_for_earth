{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "# To view tensorboard metrics\n",
    "# tensorboard --logdir=logs --port=6006 --bind_all\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from functools import partial\n",
    "from evolver import CrossoverType, MutationType, MatrixEvolver\n",
    "from unet import UNet\n",
    "from dataset_utils import PartitionType\n",
    "from cuda_utils import maybe_get_cuda_device, clear_cuda\n",
    "from landcover_dataloader import get_landcover_dataloaders\n",
    "\n",
    "from ignite.contrib.handlers.tensorboard_logger import *\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, ConfusionMatrix, mIoU\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.utils import setup_logger\n",
    "\n",
    "# Define directories for data, logging and model saving.\n",
    "base_dir = os.getcwd()\n",
    "dataset_name = \"landcover_large\"\n",
    "dataset_dir = os.path.join(base_dir, \"data/\" + dataset_name)\n",
    "\n",
    "experiment_name = \"dropout_finetuning\"\n",
    "model_name = \"best_model_30_validation_accuracy=0.9409.pt\"\n",
    "model_path = os.path.join(base_dir, \"logs/\" + dataset_name + \"/\" + model_name)\n",
    "log_dir = os.path.join(base_dir, \"logs/\" + dataset_name + \"_\" + experiment_name)\n",
    "\n",
    "# Create DataLoaders for each partition of Landcover data.\n",
    "dataloader_params = {\n",
    "    'batch_size': 16,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 6,\n",
    "    'pin_memory': True}\n",
    "\n",
    "partition_types = [PartitionType.TRAIN, PartitionType.VALIDATION, \n",
    "                   PartitionType.FINETUNING, PartitionType.TEST]\n",
    "data_loaders = get_landcover_dataloaders(dataset_dir, \n",
    "                                         partition_types,\n",
    "                                         dataloader_params,\n",
    "                                         force_create_dataset=False)\n",
    "\n",
    "train_loader = data_loaders[0]\n",
    "finetuning_loader = data_loaders[2]\n",
    "test_loader = data_loaders[3]\n",
    "\n",
    "# Get GPU device if available.\n",
    "device = maybe_get_cuda_device()\n",
    "\n",
    "# Determine model and training params.\n",
    "params = {\n",
    "    'max_epochs': 10,\n",
    "    'n_classes': 4,\n",
    "    'in_channels': 4,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'log_steps': 1,\n",
    "    'save_top_n_models': 4,\n",
    "    'num_children': 30\n",
    "}\n",
    "\n",
    "clear_cuda()    \n",
    "model = UNet(in_channels = params['in_channels'],\n",
    "             n_classes = params['n_classes'],\n",
    "             depth = params['depth'])\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=params['learning_rate'])\n",
    "\n",
    "# Determine metrics for evaluation.\n",
    "train_metrics = {\n",
    "        \"accuracy\": Accuracy(), \n",
    "        \"loss\": Loss(criterion),\n",
    "        \"mean_iou\": mIoU(ConfusionMatrix(num_classes = params['n_classes'])),\n",
    "        }\n",
    "\n",
    "validation_metrics = {\n",
    "        \"accuracy\": Accuracy(), \n",
    "        \"loss\": Loss(criterion),\n",
    "        \"mean_iou\": mIoU(ConfusionMatrix(num_classes = params['n_classes'])),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('start', torch.Size([16, 64, 256, 256])), ('down_0', torch.Size([16, 128, 128, 128])), ('down_1', torch.Size([16, 256, 64, 64])), ('down_2', torch.Size([16, 512, 32, 32])), ('down_3', torch.Size([16, 1024, 16, 16])), ('down_4', torch.Size([16, 2048, 8, 8])), ('up_0', torch.Size([16, 1024, 16, 16])), ('up_1', torch.Size([16, 512, 32, 32])), ('up_2', torch.Size([16, 256, 64, 64])), ('up_3', torch.Size([16, 128, 128, 128])), ('up_4', torch.Size([16, 64, 256, 256])), ('end', torch.Size([16, 4, 256, 256]))]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    batch_x = batch[0].to(device)\n",
    "    _ = model(batch_x)\n",
    "    break\n",
    "    \n",
    "drop_names_sizes = model.get_dropout_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "evolver = MatrixEvolver(sizes, CrossoverType.UNIFORM, MutationType.FLIP_BIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_finetune_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        batch_x, batch_y = batch\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        loss = sys.float_info.max\n",
    "        for i in range(params['num_children'])\n",
    "            child = evolver.spawn_child()\n",
    "            model.set_dropout_masks(child)\n",
    "            outputs = model(batch_y)\n",
    "            current_loss = criterion(outputs, batch_y).item()\n",
    "            evolver.add_child(child, loss)\n",
    "            loss = min(loss, current_loss)\n",
    "\n",
    "        pred = model(batch_y)\n",
    "        evolver.update_parents()\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Create Trainer or Evaluators\n",
    "trainer = Engine(dropout_finetune_step)\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=train_metrics, device=device)\n",
    "\n",
    "\n",
    "validation_evaluator = create_supervised_evaluator(model, metrics=validation_metrics, device=device)\n",
    "\n",
    "trainer.logger = setup_logger(\"Trainer\")\n",
    "train_evaluator.logger = setup_logger(\"Train Evaluator\")\n",
    "\n",
    "\n",
    "validation_evaluator.logger = setup_logger(\"Validation Evaluator\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=1))\n",
    "def report_evolver_stats(engine):\n",
    "    gen_stats = evolver.get_generation_stats()\n",
    "    for metric, value in gen_stats.items():\n",
    "        tb_logger.log_scalar(metric, value, engine.state.step)\n",
    "\n",
    "# Tensorboard Logger setup below based on pytorch ignite example\n",
    "# https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_tensorboard_logger.py\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_metrics(engine):\n",
    "    \"\"\"Callback to compute metrics on the train and validation data.\"\"\"\n",
    "    train_evaluator.run(finetuning_loader)\n",
    "    validation_evaluator.run(test_loader)\n",
    "\n",
    "def score_function(engine):\n",
    "    \"\"\"Function to determine the metric upon which to compare model.\"\"\"\n",
    "    return engine.state.metrics[\"accuracy\"]\n",
    "    \n",
    "# Setup Tensor Board Logging    \n",
    "tb_logger = TensorboardLogger(log_dir=log_dir)\n",
    "\n",
    "tb_logger.attach_output_handler(\n",
    "    trainer,\n",
    "    event_name=Events.ITERATION_COMPLETED(every=params['log_steps']),\n",
    "    tag=\"dropout_finetuning\",\n",
    "    output_transform=lambda loss: {\"batchloss\": loss},\n",
    "    metric_names=\"all\",\n",
    ")\n",
    "\n",
    "for tag, evaluator in [(\"dropout_finetuning\", train_evaluator), (\"test\", validation_evaluator)]:\n",
    "    tb_logger.attach_output_handler(\n",
    "        evaluator,\n",
    "        event_name=Events.EPOCH_COMPLETED,\n",
    "        tag=tag,\n",
    "        metric_names=\"all\",\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    "    )\n",
    "\n",
    "tb_logger.attach_opt_params_handler(trainer, \n",
    "                                    event_name=Events.ITERATION_COMPLETED(every=params['log_steps']), \n",
    "                                    optimizer=optimizer)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    log_dir,\n",
    "    n_saved=params['save_top_n_models'],\n",
    "    filename_prefix=\"best\",\n",
    "    score_function=score_function,\n",
    "    score_name=\"validation_accuracy\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "validation_evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\"model\": model})\n",
    "trainer.run(finetuning_loader, max_epochs=params['max_epochs'])\n",
    "tb_logger.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
