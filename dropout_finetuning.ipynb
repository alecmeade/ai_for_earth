{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from evolver import CrossoverType, MutationType, MatrixEvolver\n",
    "from unet import UNet\n",
    "from landcover_data_loader import LandcoverDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data\n",
    "params = {'batch_size': 16,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 6}\n",
    "\n",
    "patch_size = (256, 256)\n",
    "\n",
    "train_samples_per_tile = 4000\n",
    "test_samples_per_tile = 1000\n",
    "\n",
    "finetuning_train_samples_per_tile = 200\n",
    "finetuning_test_samples_per_tile = 800\n",
    "\n",
    "# Data Generators\n",
    "train_x_path = \"/mnt/blobfuse/esri-naip/v002/md/2015/md_100cm_2015/39076/m_3907639_sw_18_1_20150815.tif\"\n",
    "train_y_path = \"/mnt/blobfuse/resampled-lc/data/v1/2015/states/md/md_1m_2015/39076/m_3907639_sw_18_1_20150815_lc.tif\"\n",
    "\n",
    "finetuning_x_path = \"/mnt/blobfuse/esri-naip/v002/md/2015/md_100cm_2015/39076/m_3907639_ne_18_1_20150815.tif\"\n",
    "finetuning_y_path = \"/mnt/blobfuse/resampled-lc/data/v1/2015/states/md/md_1m_2015/39076/m_3907639_ne_18_1_20150815_lc.tif\"\n",
    "\n",
    "\n",
    "train_set = LandCoverDataset(train_x_path, train_y_path, patch_size, train_samples_per_tile)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, **params)\n",
    "\n",
    "# Create a test set on the same tile excluding points in the train set.\n",
    "test_set = LandCoverDataset(train_x_path, train_y_path, patch_size, test_samples_per_tile, \n",
    "                            exclude_coordinates = train_set.patch_coordinates)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(train_set, **params)\n",
    "\n",
    "finetuning_train_set = LandCoverDataset(finetuning_x_path, finetuning_y_path, patch_size, finetuning_train_samples_per_tile)\n",
    "finetuning_train_loader = torch.utils.data.DataLoader(finetuning_test_set, **params)\n",
    "\n",
    "finetuning_test_set = LandCoverDataset(finetuning_x_path, finetuning_y_path, patch_size, finetuning_test_samples_per_tile,\n",
    "                                       exclude_coordinates = finetuning_train_set.patch_coordinates)\n",
    "finetuning_test_loader = torch.utils.data.DataLoader(finetuning_test_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to clear any data associated with batch_x and batch_y on the GPU. This only needs\n",
    "# to be run if training was interupted.\n",
    "# del batch_x, batch_y; \n",
    "# del net\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1,  Batch: 10, Epoch Percent: 3.20]\n",
      "[Epoch: 1,  Batch: 20, Epoch Percent: 6.40]\n",
      "[Epoch: 1,  Batch: 30, Epoch Percent: 9.60]\n",
      "[Epoch: 1,  Batch: 40, Epoch Percent: 12.80]\n",
      "[Epoch: 1,  Batch: 50, Epoch Percent: 16.00]\n",
      "[Epoch: 1,  Batch: 60, Epoch Percent: 19.20]\n",
      "[Epoch: 1,  Batch: 70, Epoch Percent: 22.40]\n",
      "[Epoch: 1,  Batch: 80, Epoch Percent: 25.60]\n",
      "[Epoch: 1,  Batch: 90, Epoch Percent: 28.80]\n",
      "[Epoch: 1,  Batch: 100, Epoch Percent: 32.00]\n",
      "[Epoch: 1,  Batch: 110, Epoch Percent: 35.20]\n",
      "[Epoch: 1,  Batch: 120, Epoch Percent: 38.40]\n",
      "[Epoch: 1,  Batch: 130, Epoch Percent: 41.60]\n",
      "[Epoch: 1,  Batch: 140, Epoch Percent: 44.80]\n",
      "[Epoch: 1,  Batch: 150, Epoch Percent: 48.00]\n",
      "[Epoch: 1,  Batch: 160, Epoch Percent: 51.20]\n",
      "[Epoch: 1,  Batch: 170, Epoch Percent: 54.40]\n",
      "[Epoch: 1,  Batch: 180, Epoch Percent: 57.60]\n",
      "[Epoch: 1,  Batch: 190, Epoch Percent: 60.80]\n",
      "[Epoch: 1,  Batch: 200, Epoch Percent: 64.00]\n",
      "[Epoch: 1,  Batch: 210, Epoch Percent: 67.20]\n",
      "[Epoch: 1,  Batch: 220, Epoch Percent: 70.40]\n",
      "[Epoch: 1,  Batch: 230, Epoch Percent: 73.60]\n",
      "[Epoch: 1,  Batch: 240, Epoch Percent: 76.80]\n",
      "[Epoch: 1,  Batch: 250, Epoch Percent: 80.00]\n",
      "[Epoch: 1,  Batch: 260, Epoch Percent: 83.20]\n",
      "[Epoch: 1,  Batch: 270, Epoch Percent: 86.40]\n",
      "[Epoch: 1,  Batch: 280, Epoch Percent: 89.60]\n",
      "[Epoch: 1,  Batch: 290, Epoch Percent: 92.80]\n",
      "[Epoch: 1,  Batch: 300, Epoch Percent: 96.00]\n",
      "[Epoch: 1,  Batch: 310, Epoch Percent: 99.20]\n",
      "[Epoch: 2,  Batch: 10, Epoch Percent: 3.20]\n",
      "[Epoch: 2,  Batch: 20, Epoch Percent: 6.40]\n",
      "[Epoch: 2,  Batch: 30, Epoch Percent: 9.60]\n",
      "[Epoch: 2,  Batch: 40, Epoch Percent: 12.80]\n",
      "[Epoch: 2,  Batch: 50, Epoch Percent: 16.00]\n",
      "[Epoch: 2,  Batch: 60, Epoch Percent: 19.20]\n",
      "[Epoch: 2,  Batch: 70, Epoch Percent: 22.40]\n",
      "[Epoch: 2,  Batch: 80, Epoch Percent: 25.60]\n",
      "[Epoch: 2,  Batch: 90, Epoch Percent: 28.80]\n",
      "[Epoch: 2,  Batch: 100, Epoch Percent: 32.00]\n",
      "[Epoch: 2,  Batch: 110, Epoch Percent: 35.20]\n",
      "[Epoch: 2,  Batch: 120, Epoch Percent: 38.40]\n",
      "[Epoch: 2,  Batch: 130, Epoch Percent: 41.60]\n",
      "[Epoch: 2,  Batch: 140, Epoch Percent: 44.80]\n",
      "[Epoch: 2,  Batch: 150, Epoch Percent: 48.00]\n",
      "[Epoch: 2,  Batch: 160, Epoch Percent: 51.20]\n",
      "[Epoch: 2,  Batch: 170, Epoch Percent: 54.40]\n",
      "[Epoch: 2,  Batch: 180, Epoch Percent: 57.60]\n",
      "[Epoch: 2,  Batch: 190, Epoch Percent: 60.80]\n",
      "[Epoch: 2,  Batch: 200, Epoch Percent: 64.00]\n",
      "[Epoch: 2,  Batch: 210, Epoch Percent: 67.20]\n",
      "[Epoch: 2,  Batch: 220, Epoch Percent: 70.40]\n",
      "[Epoch: 2,  Batch: 230, Epoch Percent: 73.60]\n",
      "[Epoch: 2,  Batch: 240, Epoch Percent: 76.80]\n",
      "[Epoch: 2,  Batch: 250, Epoch Percent: 80.00]\n",
      "[Epoch: 2,  Batch: 260, Epoch Percent: 83.20]\n",
      "[Epoch: 2,  Batch: 270, Epoch Percent: 86.40]\n",
      "[Epoch: 2,  Batch: 280, Epoch Percent: 89.60]\n",
      "[Epoch: 2,  Batch: 290, Epoch Percent: 92.80]\n",
      "[Epoch: 2,  Batch: 300, Epoch Percent: 96.00]\n",
      "[Epoch: 2,  Batch: 310, Epoch Percent: 99.20]\n",
      "[Epoch: 3,  Batch: 10, Epoch Percent: 3.20]\n",
      "[Epoch: 3,  Batch: 20, Epoch Percent: 6.40]\n",
      "[Epoch: 3,  Batch: 30, Epoch Percent: 9.60]\n",
      "[Epoch: 3,  Batch: 40, Epoch Percent: 12.80]\n",
      "[Epoch: 3,  Batch: 50, Epoch Percent: 16.00]\n",
      "[Epoch: 3,  Batch: 60, Epoch Percent: 19.20]\n",
      "[Epoch: 3,  Batch: 70, Epoch Percent: 22.40]\n",
      "[Epoch: 3,  Batch: 80, Epoch Percent: 25.60]\n",
      "[Epoch: 3,  Batch: 90, Epoch Percent: 28.80]\n",
      "[Epoch: 3,  Batch: 100, Epoch Percent: 32.00]\n",
      "[Epoch: 3,  Batch: 110, Epoch Percent: 35.20]\n",
      "[Epoch: 3,  Batch: 120, Epoch Percent: 38.40]\n",
      "[Epoch: 3,  Batch: 130, Epoch Percent: 41.60]\n",
      "[Epoch: 3,  Batch: 140, Epoch Percent: 44.80]\n",
      "[Epoch: 3,  Batch: 150, Epoch Percent: 48.00]\n",
      "[Epoch: 3,  Batch: 160, Epoch Percent: 51.20]\n",
      "[Epoch: 3,  Batch: 170, Epoch Percent: 54.40]\n",
      "[Epoch: 3,  Batch: 180, Epoch Percent: 57.60]\n",
      "[Epoch: 3,  Batch: 190, Epoch Percent: 60.80]\n",
      "[Epoch: 3,  Batch: 200, Epoch Percent: 64.00]\n",
      "[Epoch: 3,  Batch: 210, Epoch Percent: 67.20]\n",
      "[Epoch: 3,  Batch: 220, Epoch Percent: 70.40]\n",
      "[Epoch: 3,  Batch: 230, Epoch Percent: 73.60]\n",
      "[Epoch: 3,  Batch: 240, Epoch Percent: 76.80]\n",
      "[Epoch: 3,  Batch: 250, Epoch Percent: 80.00]\n",
      "[Epoch: 3,  Batch: 260, Epoch Percent: 83.20]\n",
      "[Epoch: 3,  Batch: 270, Epoch Percent: 86.40]\n",
      "[Epoch: 3,  Batch: 280, Epoch Percent: 89.60]\n",
      "[Epoch: 3,  Batch: 290, Epoch Percent: 92.80]\n",
      "[Epoch: 3,  Batch: 300, Epoch Percent: 96.00]\n",
      "[Epoch: 3,  Batch: 310, Epoch Percent: 99.20]\n",
      "[Epoch: 4,  Batch: 10, Epoch Percent: 3.20]\n",
      "[Epoch: 4,  Batch: 20, Epoch Percent: 6.40]\n",
      "[Epoch: 4,  Batch: 30, Epoch Percent: 9.60]\n",
      "[Epoch: 4,  Batch: 40, Epoch Percent: 12.80]\n",
      "[Epoch: 4,  Batch: 50, Epoch Percent: 16.00]\n",
      "[Epoch: 4,  Batch: 60, Epoch Percent: 19.20]\n",
      "[Epoch: 4,  Batch: 70, Epoch Percent: 22.40]\n",
      "[Epoch: 4,  Batch: 80, Epoch Percent: 25.60]\n",
      "[Epoch: 4,  Batch: 90, Epoch Percent: 28.80]\n",
      "[Epoch: 4,  Batch: 100, Epoch Percent: 32.00]\n",
      "[Epoch: 4,  Batch: 110, Epoch Percent: 35.20]\n",
      "[Epoch: 4,  Batch: 120, Epoch Percent: 38.40]\n",
      "[Epoch: 4,  Batch: 130, Epoch Percent: 41.60]\n",
      "[Epoch: 4,  Batch: 140, Epoch Percent: 44.80]\n",
      "[Epoch: 4,  Batch: 150, Epoch Percent: 48.00]\n",
      "[Epoch: 4,  Batch: 160, Epoch Percent: 51.20]\n",
      "[Epoch: 4,  Batch: 170, Epoch Percent: 54.40]\n",
      "[Epoch: 4,  Batch: 180, Epoch Percent: 57.60]\n",
      "[Epoch: 4,  Batch: 190, Epoch Percent: 60.80]\n",
      "[Epoch: 4,  Batch: 200, Epoch Percent: 64.00]\n",
      "[Epoch: 4,  Batch: 210, Epoch Percent: 67.20]\n",
      "[Epoch: 4,  Batch: 220, Epoch Percent: 70.40]\n",
      "[Epoch: 4,  Batch: 230, Epoch Percent: 73.60]\n",
      "[Epoch: 4,  Batch: 240, Epoch Percent: 76.80]\n",
      "[Epoch: 4,  Batch: 250, Epoch Percent: 80.00]\n",
      "[Epoch: 4,  Batch: 260, Epoch Percent: 83.20]\n",
      "[Epoch: 4,  Batch: 270, Epoch Percent: 86.40]\n",
      "[Epoch: 4,  Batch: 280, Epoch Percent: 89.60]\n",
      "[Epoch: 4,  Batch: 290, Epoch Percent: 92.80]\n",
      "[Epoch: 4,  Batch: 300, Epoch Percent: 96.00]\n",
      "[Epoch: 4,  Batch: 310, Epoch Percent: 99.20]\n",
      "[Epoch: 5,  Batch: 10, Epoch Percent: 3.20]\n",
      "[Epoch: 5,  Batch: 20, Epoch Percent: 6.40]\n",
      "[Epoch: 5,  Batch: 30, Epoch Percent: 9.60]\n",
      "[Epoch: 5,  Batch: 40, Epoch Percent: 12.80]\n",
      "[Epoch: 5,  Batch: 50, Epoch Percent: 16.00]\n",
      "[Epoch: 5,  Batch: 60, Epoch Percent: 19.20]\n",
      "[Epoch: 5,  Batch: 70, Epoch Percent: 22.40]\n",
      "[Epoch: 5,  Batch: 80, Epoch Percent: 25.60]\n",
      "[Epoch: 5,  Batch: 90, Epoch Percent: 28.80]\n",
      "[Epoch: 5,  Batch: 100, Epoch Percent: 32.00]\n",
      "[Epoch: 5,  Batch: 110, Epoch Percent: 35.20]\n",
      "[Epoch: 5,  Batch: 120, Epoch Percent: 38.40]\n",
      "[Epoch: 5,  Batch: 130, Epoch Percent: 41.60]\n",
      "[Epoch: 5,  Batch: 140, Epoch Percent: 44.80]\n",
      "[Epoch: 5,  Batch: 150, Epoch Percent: 48.00]\n",
      "[Epoch: 5,  Batch: 160, Epoch Percent: 51.20]\n",
      "[Epoch: 5,  Batch: 170, Epoch Percent: 54.40]\n",
      "[Epoch: 5,  Batch: 180, Epoch Percent: 57.60]\n",
      "[Epoch: 5,  Batch: 190, Epoch Percent: 60.80]\n",
      "[Epoch: 5,  Batch: 200, Epoch Percent: 64.00]\n",
      "[Epoch: 5,  Batch: 210, Epoch Percent: 67.20]\n",
      "[Epoch: 5,  Batch: 220, Epoch Percent: 70.40]\n",
      "[Epoch: 5,  Batch: 230, Epoch Percent: 73.60]\n",
      "[Epoch: 5,  Batch: 240, Epoch Percent: 76.80]\n",
      "[Epoch: 5,  Batch: 250, Epoch Percent: 80.00]\n",
      "[Epoch: 5,  Batch: 260, Epoch Percent: 83.20]\n",
      "[Epoch: 5,  Batch: 270, Epoch Percent: 86.40]\n",
      "[Epoch: 5,  Batch: 280, Epoch Percent: 89.60]\n",
      "[Epoch: 5,  Batch: 290, Epoch Percent: 92.80]\n",
      "[Epoch: 5,  Batch: 300, Epoch Percent: 96.00]\n",
      "[Epoch: 5,  Batch: 310, Epoch Percent: 99.20]\n"
     ]
    }
   ],
   "source": [
    "# Define Model Loss and Optimizers\n",
    "max_epochs = 10\n",
    "report_batches = 25\n",
    "net = UNet(in_channels = 4, n_classes = train_set.n_classes, depth = 4)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        batch_x, batch_y = data\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(batch_x)\n",
    "\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % report_batches == report_batches - 1:\n",
    "            print('TRAIN: [Epoch: %d,  Batch: %d, Epoch Percent: %0.2f, Avg Loss: %3d]' % (epoch + 1, \n",
    "                                                                                           i + 1, \n",
    "                                                                                           100 * train_loader.batch_size * (i + 1) / train_set.n_samples),\n",
    "                                                                                           running_loss / (report_batches * train_loader.batch_size))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        batch_x, batch_y = data\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device) \n",
    "        outputs = net(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('TEST: [Avg Batch Loss: %3d]' % (running_loss / ((i + 1) * test_loader.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hook in unet to set dropout on up and down layers.\n",
    "# consider a set dropout layer function for up or down layer\n",
    "\n",
    "# create hook in unet to get layer dimensions of the outputs to each layer after conv b\n",
    "# scale dropout mask before applying it\n",
    "# consider adding \"temperature\" or learning rate adjustment to mutation and cross over types.\n",
    "# add cross over type best.\n",
    "\n",
    "# finish commenting matrix evolver.\n",
    "dropout_mask_evolver = MatrixEvolver([[3, 3]], CrossoverType.UNIFORM, MutationType.FLIP_BIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in net.parameters():\n",
    "#     print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
